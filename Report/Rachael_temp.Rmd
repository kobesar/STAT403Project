---
title: "Rachael Temp"
author: "Rachael Ren"
date: "2023-06-04"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(glmnet)
```

# Logistic Regression
We decided to use logistic regression to predict our binary response: whether a given respondent would vote for Biden or not Biden. We decided to use the following predictors for our initial model: age, sex, education, income, size place, voting method, LGBT, region, racism, abortion, life, climate change, and face mask. The first eight predictors listed are responses to demographic questions and the latter five are responses to opinion questions (see Introduction for more details on the variables).

These predictors were selected because we were interested in whether they would be significant predictors for who a respondent voted for. We excluded obvious variables, such as who they voted for in 2016 and party affiliation, since the main purpose of this model was to see which predictors were significant rather than prediction. 

Since all of our predictors were categorical, we used one-hot encoding to relevel the categories. The following levels were set as the reference:

\begin{tabular}{c|c}
\hline
  Predictor & Reference level\\
  \hline
  age & 18-29\\
  sex & Female\\
  education & Never attended college\\
  income & Omit\\
  size place & Rural\\
  voting method & Election day\\
  LGBT & Omit\\
  region & South\\
  racism & Omit\\
  abortion & Omit\\
  life & Omit\\
  climate change & Omit
\end{tabular}

Below is the summary output for our initial model:

```{r, include = FALSE}
cols <- str_split("age
sex
educ18
income20
racism20
life
region
sizeplac
pres
votemeth
abortion
facemask
lgbt
climatec", "\n")[[1]]

data <- read.csv("../Data/31119913_National2020.csv")

data_subset <- data[, cols]

data_subset[data_subset == " "] <- "Omit"

data_subset$age = relevel(factor(data_subset$age), ref = "18-29")
data_subset$sex = relevel(factor(data_subset$sex), ref = "Female")
data_subset$educ18 = relevel(factor(data_subset$educ18), ref = "Never attended college")
data_subset$income20 = relevel(factor(data_subset$income20), ref = "Omit")
data_subset$racism20 = relevel(factor(data_subset$racism20), ref = "Omit")
data_subset$life = relevel(factor(data_subset$life), ref = "Omit")
data_subset$region = relevel(factor(data_subset$region), ref = "South")
data_subset$sizeplac = relevel(factor(data_subset$sizeplac), ref = "Suburbs")
data_subset$votemeth = relevel(factor(data_subset$votemeth), ref = "Election day")
data_subset$abortion = relevel(factor(data_subset$abortion), ref = "Omit")
data_subset$facemask = relevel(factor(data_subset$facemask), ref = "Omit")
data_subset$lgbt = relevel(factor(data_subset$lgbt), ref = "Omit")
data_subset$climatec = relevel(factor(data_subset$climatec), ref = "Omit")

X <- model.matrix(pres ~ ., data_subset)[,-1]
Y <- data_subset$pres == "Joe Biden"

data_full <- data.frame(cbind(Y, X))

mod <- glm(Y ~ ., family = "binomial", data = data_full)

summary(mod)
```

## Final Model

After building our initial model, we ran backwards stepwise BIC, which resulted in our final model:

$\hat{\text{president}} = \beta_0 + \beta_1(\text{age}) + \beta_2(\text{sex}) + \beta_3(\text{education}) + \beta_4(\text{income}) + \beta_5(\text{racism}) + $

$\beta_6(\text{size place}) + \beta_7(\text{voting method}) + \beta_8(\text{abortion}) + \beta_9(\text{climate change})$

```{r, include = FALSE}
mod_step <- step(mod, direction = "backward", k = log(nrow(data_full)))

summary(mod_step)
```

Each coefficient estimate indicates the change in log odds for voting Biden in comparison with the reference level. As we can see from the model output, at least one level for each predictor was significant at the $\alpha = 0.05$ level. The only predictors omitted from our final model were whether a respondent identified as LGBT, their opinion on face masks, and which region of the US they were from. Note that due to the nature of our predictors, there is likely collinearity.

# Results

Some notable trends our model predicted were:

1. As education level increased, the more likely they were to vote for Biden.

2. The more a respondent considered racism to be a problem, the more likely they were to vote for Biden.

3. If a respondent voted by mail or early in-person, they were more likely to vote for Biden. The positive coefficient associated with voting by mail may have been due to COVID-19 concerns in 2020. The positive coefficients for both levels accurately describe voting behavior in 2020. Early polls tended to overstate Biden's lead in the election (Keeter et al., 2021).

4. Men were less likely to vote for Biden and people who omitted sex, which likely included non-binary individuals, were more likely to vote for Biden.

5. The more a respondent favored the right to abortion, the more likely they were to vote for Biden.

6. If a respondent did not believe in climate change, they were much less likely to vote for Biden.

Trends for other predictors were less clear, but still significant.

# Model Validation

We validated our final model by creating a confusion matrix for our test data.

```{r, include = FALSE}
train <- readRDS("../data/data_train.RDS")
test <- readRDS("../data/data_test.RDS")

mod_final <- glm(Y_final ~ ., family = "binomial", data = train)

actual <- test$Y_final
predicted <- (predict(mod_final, test, type = "response") > 0.5)*1

# Create a data frame with the actual and predicted labels
data <- data.frame(actual, predicted)

cm_data <- data %>% 
  group_by(actual, predicted) %>% 
  summarize(n = n()) %>% 
  mutate(actual = as.character(actual), predicted = as.character(predicted))

cm_data$actual <- factor(cm_data$actual, levels = c("1", "0"))
cm_data$predicted <- factor(cm_data$predicted, levels = c("0", "1"))
cm_data$labels <- c("True Negatives", "False Positives", "False Negatives", "True Positives")

cm_data <- cm_data %>% 
  mutate(labels = paste0(n, "\n", labels))

# Plot the confusion matrix using ggplot
cm_plot <- cm_data %>% 
  ggplot(aes(x = actual, y = predicted, fill = n)) +
  geom_tile() +
  geom_label(aes(label = labels), color = "black", size = 4, fill = "gray90") +
  scale_fill_gradient(low = "white", high = "#2a3990") +
  scale_x_discrete(labels = c("", "")) +
  scale_y_discrete(labels = c("", "")) +
  labs(title = "Confusion Matrix", 
       x = "", 
       y = "",
       subtitle = paste(
         "Recall: ", round(cm_data[cm_data$actual == "1" & cm_data$predicted == "1",]$n/(cm_data[cm_data$actual == "0" & cm_data$predicted == "1",]$n + cm_data[cm_data$actual == "1" & cm_data$predicted == "1",]$n), 2),
         " | Precision: ", round(cm_data[cm_data$actual == "1" & cm_data$predicted == "1",]$n/(cm_data[cm_data$actual == "1" & cm_data$predicted == "1",]$n + cm_data[cm_data$actual == "1" & cm_data$predicted == "0",]$n), 2),
         " | Accuracy: ", round(sum(cm_data[cm_data$actual == cm_data$predicted,]$n)/sum(cm_data$n), 2))) +
  theme_minimal()
cm_plot
```

As we can see from the confusion matrix, our model performed relatively well. The recall, precision, and accuracy of our model were 0.68, 0.73, and 0.69, respectively. However, recall that the primary purpose of our model was to determine which predictors were significant, rather than obtaining the highest accuracy.