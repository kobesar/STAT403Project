x[,30] <- x[, 1] * 1.5 + rnorm(200)
index <- sample(2:29, 4)
x_sub <- x[, index]
coeff <- runif(5, -5, 4)
y <- x[,1]
for(i in 1:4) {
y <- y + coeff[i] * x_sub[, i]
}
y <- y + rnorm(200)
splt <- sample(nrow(x), nrow(x)* 0.8)
x_train <- x[splt,]
x_test <- x[-splt,]
y_train <- y[splt]
y_test <- y[-splt]
summary(regsubsets(y_train ~ ., data = data.frame(x_train), method = "forward", nvmax = 10))$outmat[10,]
lm1 <- lm(y_train ~ X1 + X3 + X5 + X6 + X9 + X13 + X18 + X22 + X26 + X28, data.frame(x_train))
ind <- c(1, 3, 5, 6, 9, 13, 18, 22, 26, 28)
x_test <- data.frame(x_test)
x_test <- x_test[,ind]
pred <- predict(lm1, data.frame(x_test))
test_mse <- mean((pred - y_test) ^ 2)
lm1 <- lm(y_train ~ X1 + X3 + X4 + X5 + X6 + X8 + X15 + X20 + X26 + X28, data.frame(x_train))
ind <- c(1, 3, 4, 5, 6, 8, 15, 20, 26, 28)
x_test <- data.frame(x_test)
x_test <- x_test[,ind]
x_test <- x[-splt,]
x_test <- data.frame(x_test)
x_test <- x_test[,ind]
pred <- predict(lm1, data.frame(x_test))
test_mse <- mean((pred - y_test) ^ 2)
lambda <- 10^seq(10, -2, length = 100)
ridge <- glmnet(x_train, y_train, alpha = 0, lambda = lambda)
cv_ridge <- cv.glmnet(x_train, y_train, alpha = 0)
coeff <- matrix(NA, nrow = 30, ncol = 100)
for (i in 1:30) {
for (j in 1:100) {
coeff[i, j] <- coef(ridge)[, j][i+1]
}
}
plot(x = log(lambda), y = coeff[1,], type = "l", ylab = "Coefficients",
ylim = c(min(coeff), max(coeff)), col = 1,
main = "Ridge Coefficients across Values of Lambda")
for(i in 2:30) {
lines(x = log(lambda), y = coeff[i,], col = i)
}
abline(h = 0, lwd = 1.5, lty = 2)
x_test <- x[-splt, ]
pred <- predict(ridge, s = cv_ridge$lambda.min, newx = x_test)
test_mse <- mean((pred - y_test)^2)
lasso <- glmnet(x_train, y_train, alpha = 1, lambda = lambda)
cv_lasso <- cv.glmnet(x_train, y_train, alpha = 1)
coeff <- matrix(NA, nrow = 30, ncol = 100)
for (i in 1:30) {
for (j in 1:100) {
coeff[i, j] <- coef(lasso)[, j][i+1]
}
}
plot(x = log(lambda), y = coeff[1,], type = "l", ylab = "Coefficients",
ylim = c(min(coeff), max(coeff)), col = 1,
main = "LASSO Coefficients across Values of Lambda")
for(i in 2:30) {
lines(x = log(lambda), y = coeff[i,], col = i)
}
abline(h = 0, lwd = 1.5, lty = 2)
View(coeff)
pred <- predict(lasso, s = cv_lasso$lambda.min, newx = x_test)
test_mse <- mean((pred - y_test)^2)
1000^2
knitr::opts_chunk$set(echo = TRUE)
data(faithful)
kde_1 <- density(faithful$eruptions, bw = 0.1)
kde_2 <- density(faithful$eruptions, bw = 0.3)
kde_3 <- density(faithful$eruptions, bw = 0.9)
plot(kde_1$x, kde_1$y, type = "l", lwd = 2, main = "KDE of Eruptions Using Different Bandwidths", xlab = "eruptions", ylab = "density", xlim = c(0, 6))
lines(kde_2$x, kde_2$y, col = "red", lwd = 2)
lines(kde_3$x, kde_3$y, col = "blue", lwd = 3)
legend("topright", c("h=0.1", "h=0.3", "h=0.9"),
col = c("black", "red", "blue"), lwd = 2)
hist(faithful$eruptions, probability = T, breaks = 20,
main = "Histogram of Eruptions", xlab = "eruptions")
lines(kde_2$x, kde_2$y, col = "red", lwd = 2)
kde_boot <- matrix(ncol = 10000, nrow = length(kde_2$x))
for(i in 1:10000) {
j <- sample(nrow(faithful), nrow(faithful), replace = T)
samp <- faithful[j,]
kde_boot[,i] <- density(samp$eruptions, bw = 0.3)$y
}
se <- sqrt(diag(var(kde_boot)))
knitr::opts_chunk$set(echo = TRUE)
data(faithful)
plot(kde_2$x, kde_2$y, type = "l")
lines(kde_2$x, kde_2$y + qnorm(0.975)*se, col = "lightblue")
kde_boot <- matrix(nrow = 10000, ncol = length(kde_2$x))
for(i in 1:10000) {
j <- sample(nrow(faithful), nrow(faithful), replace = T)
samp <- faithful[j,]
kde_boot[i,] <- density(samp$eruptions, bw = 0.3)$y
}
se <- sqrt(diag(var(kde_boot)))
plot(kde_2$x, kde_2$y, type = "l")
lines(kde_2$x, kde_2$y + qnorm(0.975)*se, col = "lightblue")
lines(kde_2$x, kde_2$y - qnorm(0.975)*se, col = "lightblue")
plot(kde_2$x, kde_2$y, type = "l", ylim = c(0, 0.55))
lines(kde_2$x, kde_2$y + qnorm(0.975)*se, col = "blue")
lines(kde_2$x, kde_2$y - qnorm(0.975)*se, col = "blue")
plot(kde_2$x, kde_2$y, type = "l", ylim = c(0, 0.55), lwd = 2)
lines(kde_2$x, kde_2$y + qnorm(0.975)*se, col = "blue")
lines(kde_2$x, kde_2$y - qnorm(0.975)*se, col = "blue")
plot(kde_2$x, kde_2$y, type = "l", ylim = c(0, 0.55), lwd = 2)
lines(kde_2$x, kde_2$y + qnorm(0.975)*se, col = "blue", lty = 2)
lines(kde_2$x, kde_2$y - qnorm(0.975)*se, col = "blue", lty = 2)
plot(kde_2$x, kde_2$y, type = "l", ylim = c(0, 0.55), lwd = 2, xlab = "eruptions", ylab = "density")
lines(kde_2$x, kde_2$y + qnorm(0.975)*se, col = "blue", lty = 2)
lines(kde_2$x, kde_2$y - qnorm(0.975)*se, col = "blue", lty = 2)
plot(kde_2$x, kde_2$y, type = "l", ylim = c(0, 0.55), lwd = 2, xlab = "eruptions", ylab = "density", main = "Confidence Interval of KDE")
lines(kde_2$x, kde_2$y + qnorm(0.975)*se, col = "blue", lty = 2)
lines(kde_2$x, kde_2$y - qnorm(0.975)*se, col = "blue", lty = 2)
install.packages(nimble)
install.packages("nimble")
knitr::opts_chunk$set(echo = TRUE)
library(nimble)
data(faithful)
dat <- rdexp(1000)
kde_dexp <- density(dat, bw = 0.2)
plot(kde_dexp$x, ddexp(kde_dexp$x))
lines(kde_dexp$x, kde_dexp$y)
dat <- rdexp(1000)
kde_dexp <- density(dat, bw = 0.2)
plot(kde_dexp$x, ddexp(kde_dexp$x), type = "l")
lines(kde_dexp$x, kde_dexp$y, col = "red")
legend("topright", c("Density", "KDE"), col = c("black", "red"), lwd = 2)
dat <- rdexp(1000)
kde_dexp <- density(dat, bw = 0.2)
plot(kde_dexp$x, ddexp(kde_dexp$x), lwd = 2, type = "l", xlab = "x",
ylab = "density", main = "Density vs Kernel of Double Exponential")
lines(kde_dexp$x, kde_dexp$y, col = "red", lwd = 2)
legend("topright", c("Density", "KDE"), col = c("black", "red"), lwd = 2)
dat <- rdexp(1000)
kde_dexp <- density(dat, bw = 0.2)
plot(kde_dexp$x, ddexp(kde_dexp$x), lwd = 2, type = "l", xlab = "x",
ylab = "density", main = "Density vs Kernel of Double Exponential")
lines(kde_dexp$x, kde_dexp$y, col = "red", lwd = 2)
legend("topright", c("Density", "KDE"), col = c("black", "red"), lwd = 2)
dat <- rdexp(1000)
kde_dexp <- density(dat, bw = 0.2)
plot(kde_dexp$x, ddexp(kde_dexp$x), lwd = 2, type = "l", xlim = c(-10, 10),
xlab = "x",  ylab = "density",
main = "Density vs Kernel of Double Exponential")
lines(kde_dexp$x, kde_dexp$y, col = "red", lwd = 2)
legend("topright", c("Density", "KDE"), col = c("black", "red"), lwd = 2)
dat <- rdexp(1000)
kde_dexp <- density(dat, bw = 0.2)
plot(kde_dexp$x, ddexp(kde_dexp$x), lwd = 2, type = "l", xlim = c(-10, 10),
xlab = "x",  ylab = "density",
main = "Density vs Kernel of Double Exponential")
lines(kde_dexp$x, kde_dexp$y, col = "red", lwd = 2)
legend("topright", c("Density", "KDE"), col = c("black", "red"), lwd = 2)
dat <- rdexp(1000)
kde_dexp <- density(dat, bw = 0.2)
plot(kde_dexp$x, ddexp(kde_dexp$x), lwd = 2, type = "l", xlim = c(-7.5, 7.5),
xlab = "x",  ylab = "density",
main = "Density vs Kernel of Double Exponential")
lines(kde_dexp$x, kde_dexp$y, col = "red", lwd = 2)
legend("topright", c("Density", "KDE"), col = c("black", "red"), lwd = 2)
knitr::opts_chunk$set(echo = TRUE)
library(nimble)
data(faithful)
set.seed(403)
dat <- rdexp(1000)
kde_dexp <- density(dat, bw = 0.2)
plot(kde_dexp$x, ddexp(kde_dexp$x), lwd = 2, type = "l", xlim = c(-6, 6),
xlab = "x",  ylab = "density",
main = "Density vs Kernel of Double Exponential")
lines(kde_dexp$x, kde_dexp$y, col = "red", lwd = 2)
legend("topright", c("Density", "KDE"), col = c("black", "red"), lwd = 2)
dat <- rdexp(1000)
kde_dexp <- density(dat, bw = 0.2)
plot(kde_dexp$x, ddexp(kde_dexp$x), lwd = 2, type = "l", xlim = c(-6, 6),
xlab = "x",  ylab = "density",
main = "Density vs Kernel of Double Exponential")
lines(kde_dexp$x, kde_dexp$y, col = "red", lwd = 2)
legend("topright", c("Density", "KDE"), col = c("black", "red"), lwd = 2)
?seq
h_seq <- seq(0.05, 0.5, by = 0.05)
mise_seq <- c()
for(i in 1:length(h_seq)) {
kde_dat <- matrix(NA, nrow = 10000, ncol = 1000)
for(j in 1:10000) {
samp <- rdexp(1000)
kde_dat[i, ] <- density(samp, from=-6, to=6, n=1000, bw=h_seq[i])$y
}
kde_mse <- colSums((t(t(kde_dat)- ddexp(kde_dexp$x)))^2)/10000
mise_seq <- sum(kde_mse)
}
length(kde_dexp$x)
true_density <- ddexp(density(dat, from=-6, to=6, n=1000, bw = 0.1)$x)
h_seq <- seq(0.05, 0.5, by = 0.05)
mise_seq <- c()
for(i in 1:length(h_seq)) {
kde_dat <- matrix(NA, nrow = 10000, ncol = 1000)
for(j in 1:10000) {
samp <- rdexp(1000)
kde_dat[i, ] <- density(samp, from=-6, to=6, n=1000, bw=h_seq[i])$y
}
kde_mse <- colSums((t(t(kde_dat)- ddexp(kde_dexp$x)))^2)/10000
mise_seq <- sum(kde_mse)
}
true_density <- ddexp(density(dat, from=-6, to=6, n=1000, bw = 0.1)$x)
h_seq <- seq(0.05, 0.5, by = 0.05)
mise_seq <- c()
for(i in 1:length(h_seq)) {
kde_dat <- matrix(NA, nrow = 10000, ncol = 1000)
for(j in 1:10000) {
samp <- rdexp(1000)
kde_dat[i, ] <- density(samp, from=-6, to=6, n=1000, bw=h_seq[i])$y
}
kde_mse <- colSums((t(t(kde_dat)- true_density))^2)/10000
mise_seq <- sum(kde_mse)
}
plot(h_seq, mise_seq, type = "l", lwd = 2)
View(kde_dat)
true_density <- ddexp(density(dat, from=-6, to=6, n=1000, bw = 0.1)$x)
h_seq <- seq(0.05, 0.5, by = 0.05)
mise_seq <- c()
for(i in 1:length(h_seq)) {
kde_dat <- matrix(NA, nrow = 10000, ncol = 1000)
for(j in 1:10000) {
samp <- rdexp(1000)
kde_dat[j, ] <- density(samp, from=-6, to=6, n=1000, bw=h_seq[i])$y
}
kde_mse <- colSums((t(t(kde_dat)- true_density))^2)/10000
mise_seq <- sum(kde_mse)
}
plot(h_seq, mise_seq, type = "l", lwd = 2)
true_density <- ddexp(density(dat, from=-6, to=6, n=1000, bw = 0.1)$x)
h_seq <- seq(0.05, 0.5, by = 0.05)
mise_seq <- c()
for(i in 1:length(h_seq)) {
kde_dat <- matrix(NA, nrow = 10000, ncol = 1000)
for(j in 1:10000) {
samp <- rdexp(1000)
kde_dat[j, ] <- density(samp, from=-6, to=6, n=1000, bw=h_seq[i])$y
}
kde_mse <- colSums((t(t(kde_dat)- true_density))^2)/10000
mise_seq[i] <- sum(kde_mse)
}
plot(h_seq, mise_seq, type = "l", lwd = 2)
knitr::opts_chunk$set(echo = TRUE)
set.seed(435)
library(leaps)
library(splines)
college <- read.csv("College.csv")
lm2 <- lm(y_train ~ Private + bs(Accept) + bs(F.Undergrad) + Room.Board + bs(Terminal) + perc.alumni + Expend + Grad.Rate, data = x_train)
splt <- sample(nrow(college), nrow(college) * 0.9)
x_train <- college[splt,-c(1,10)]
x_test <- college[-splt,-c(1,10)]
y_train <- college[splt,10]
y_test <- college[-splt, 10]
lm2 <- lm(y_train ~ Private + bs(Accept) + bs(F.Undergrad) + Room.Board + bs(Terminal) + perc.alumni + Expend + Grad.Rate, data = x_train)
pred <- predict(lm2, x_test)
test_mse <- mean((pred - y_test)^2)
seeds <- read.table("seeds.txt")
seeds <- read.table("seeds.txt", header = T, sep = ",")
View(seeds)
splt <- sample(nrow(seeds), 150)
?lda
View(seeds)
knitr::opts_chunk$set(echo = TRUE)
set.seed(435)
library(leaps)
library(splines)
library(MASS)
college <- read.csv("College.csv")
seeds <- read.table("seeds.txt", header = T, sep = ",")
j <- sample(150, 150, replace = T)
samp <- train[j,]
splt <- sample(nrow(seeds), 150)
train <- seeds[splt,]
test <- seeds[-splt,]
j <- sample(150, 150, replace = T)
samp <- train[j,]
lda1 <- lda(Y ~ A + P + l + w + asym + groove, data = seeds)
j <- sample(150, 150, replace = T)
samp <- train[j,]
lda1 <- lda(Y ~ A + P + l + w + asym + groove, data = seeds)
lda_pred <- predict(lda1, test)
test_err <- mean(lda_pred != test$Y)
View(lda_pred)
j <- sample(150, 150, replace = T)
samp <- train[j,]
lda1 <- lda(Y ~ A + P + l + w + asym + groove, data = seeds)
lda_pred <- predict(lda1, test)
test_err <- mean(lda_pred$class != test$Y)
table(Actual = test$Y, Predicted = lda_pred$class)
knitr::opts_chunk$set(echo = TRUE)
set.seed(435)
library(leaps)
library(splines)
library(MASS)
library(class)
college <- read.csv("College.csv")
seeds <- read.table("seeds.txt", header = T, sep = ",")
j <- sample(150, 150, replace = T)
samp <- train[j,]
min_k <- 0
test_err_k <- c()
best_pred <- 0
for(i in 3:30) {
knn_pred <- knn(samp[-"Y"], test[-"Y"], samp$Y, i)
test_err <- c(test_err, mean(knn_pred != test$Y))
if(test_err[i-2] == min(test_err)) {
min_k <- i
best_pred <- knn_pred
}
}
j <- sample(150, 150, replace = T)
samp <- train[j,]
min_k <- 0
test_err_k <- c()
best_pred <- 0
for(i in 3:30) {
knn_pred <- knn(samp[,-8], test[,-"Y"], samp$Y, i)
test_err <- c(test_err, mean(knn_pred != test$Y))
if(test_err[i-2] == min(test_err)) {
min_k <- i
best_pred <- knn_pred
}
}
j <- sample(150, 150, replace = T)
samp <- train[j,]
min_k <- 0
test_err_k <- c()
best_pred <- 0
for(i in 3:30) {
knn_pred <- knn(samp[,-8], test[,-8], samp$Y, i)
test_err <- c(test_err, mean(knn_pred != test$Y))
if(test_err[i-2] == min(test_err)) {
min_k <- i
best_pred <- knn_pred
}
}
table(Actual = test$Y, Predicted = best_pred)
j <- sample(150, 150, replace = T)
samp <- train[j,]
min_k <- 0
test_err_k <- c()
best_pred <- 0
for(i in 3:30) {
knn_pred <- knn(samp[,-8], test[,-8], samp$Y, i)
test_err_k <- c(test_err, mean(knn_pred != test$Y))
if(test_err[i-2] == min(test_err_k)) {
min_k <- i
best_pred <- knn_pred
}
}
table(Actual = test$Y, Predicted = best_pred)
test_err_k
j <- sample(150, 150, replace = T)
samp <- train[j,]
min_k <- 0
test_err_k <- c()
best_pred <- 0
for(i in 3:30) {
knn_pred <- knn(samp[,-8], test[,-8], samp$Y, i)
test_err_k <- c(test_err_k, mean(knn_pred != test$Y))
if(test_err[i-2] == min(test_err_k)) {
min_k <- i
best_pred <- knn_pred
}
}
table(Actual = test$Y, Predicted = best_pred)
test_err_k
j <- sample(150, 150, replace = T)
samp <- train[j,]
min_k <- 0
test_err_k <- c()
best_pred <- 0
for(i in 3:30) {
knn_pred <- knn(samp[,-8], test[,-8], samp$Y, i)
test_err_k[i-2] <- mean(knn_pred != test$Y)
if(test_err[i-2] == min(test_err_k)) {
min_k <- i
best_pred <- knn_pred
}
}
table(Actual = test$Y, Predicted = best_pred)
min(test_err_k)
test_err_k
j <- sample(150, 150, replace = T)
samp <- train[j,]
min_k <- 0
test_err_k <- c()
best_pred <- 0
for(i in 3:30) {
knn_pred <- knn(samp[,-8], test[,-8], samp$Y, i)
test_err_k[i-2] <- mean(knn_pred != test$Y)
if(test_err[i-2] < min(test_err_k)) {
min_k <- i
best_pred <- knn_pred
}
}
table(Actual = test$Y, Predicted = best_pred)
j <- sample(150, 150, replace = T)
samp <- train[j,]
k0 <- 0
test_err_k <- c()
best_pred <- 0
min_err <- 100000
for(i in 3:30) {
knn_pred <- knn(samp[,-8], test[,-8], samp$Y, i)
test_err_temp <- mean(knn_pred != test$Y)
if(test_err_temp < min_err) {
k0 <- i
best_pred <- knn_pred
min_err <- test_err_temp
}
}
table(Actual = test$Y, Predicted = best_pred)
cluster_data <- data.frame(X1 = c(3,6,0,2,4,5), X2 = C(1,2,4,1,8,0), label = as.factor(c(1,2,2,1,1,2)))
cluster_data <- data.frame(X1 = c(3,6,0,2,4,5), X2 = C(1,2,4,1,8,0), label = factor(c(1,2,2,1,1,2)))
factor
?factor
cluster_data <- data.frame(X1 = c(3,6,0,2,4,5), X2 = C(1,2,4,1,8,0), label = factor(c(1,2,2,1,1,2), levels = c(1,2)))
cluster_data <- data.frame(X1 = c(3,6,0,2,4,5), X2 = C(1,2,4,1,8,0), label = c(1,2,2,1,1,2))
cluster_data <- data.frame(X1 = c(3,6,0,2,4,5), X2 = c(1,2,4,1,8,0), label = c(1,2,2,1,1,2))
plot(cluster_data$X1, cluster_data$X2, col = label, pch = 19)
cluster_data <- data.frame(X1 = c(3,6,0,2,4,5), X2 = c(1,2,4,1,8,0), label = c(1,2,2,1,1,2))
plot(cluster_data$X1, cluster_data$X2, col = cluster$label, pch = 19)
cluster_data <- data.frame(X1 = c(3,6,0,2,4,5), X2 = c(1,2,4,1,8,0), label = c(1,2,2,1,1,2))
plot(cluster_data$X1, cluster_data$X2, col = cluster_data$label, pch = 19)
plot(cluster_data$X1, cluster_data$X2, col = cluster_data$label, pch = 19,
xlab = "X1", ylab = "X2")
cluster_data <- data.frame(X1 = c(3,6,0,2,4,5), X2 = c(1,2,4,1,8,0), label = c(1,2,2,1,1,2))
plot(cluster_data$X1, cluster_data$X2, col = cluster_data$label, pch = 19,
xlab = "X1", ylab = "X2")
legend("topright", c("1", "2"), col = c("black", "red"), pch = 19)
View(cluster_data)
knitr::opts_chunk$set(echo = TRUE)
data(rock)
kde1 <- ksmooth(rock$peri, rock$area, kernel = "normal", bandwidth = 500)
plot(rock$peri, rock$area, pch = 19, xlab = "peri", ylab = "area")
lines(rock$peri, kde1)
kde1 <- ksmooth(rock$peri, rock$area, kernel = "normal", bandwidth = 500)
plot(rock$peri, rock$area, pch = 19, xlab = "peri", ylab = "area")
lines(kde1)
kde1 <- ksmooth(rock$peri, rock$area, kernel = "normal", bandwidth = 500)
plot(rock$peri, rock$area, pch = 19, xlab = "peri", ylab = "area")
lines(kde1, lwd = 2)
kde2 <- ksmooth(rock$peri, rock$area, kernel = "normal", bandwidth = 250)
kde3 <- ksmooth(rock$peri, rock$area, kernel = "normal", bandwidth = 1000)
plot(rock$peri, rock$area, pch = 19, xlab = "peri", ylab = "area")
lines(kde2, lwd = 2, col = "red")
lines(kde1, lwd = 2)
lines(kde2, lwd = 2, col = "blue")
legend("bottomright", c("250", "500", "1000"), col = c("red", "black", "blue"),
lwd = 2)
kde2 <- ksmooth(rock$peri, rock$area, kernel = "normal", bandwidth = 250)
kde3 <- ksmooth(rock$peri, rock$area, kernel = "normal", bandwidth = 1000)
plot(rock$peri, rock$area, pch = 19, xlab = "peri", ylab = "area")
lines(kde2, lwd = 2, col = "red")
lines(kde1, lwd = 2)
lines(kde3, lwd = 2, col = "blue")
legend("bottomright", c("250", "500", "1000"), col = c("red", "black", "blue"),
lwd = 2)
install.packages("MASS")
install.packages("randomForest")
library(tidyverse)
library(glmnet)
library(ggalt)
cols <- str_split("age
sex
educ18
income20
racism20
life
region
sizeplac
pres
votemeth
abortion
facemask
lgbt
climatec", "\n")[[1]]
data <- read.csv("../Data/31119913_National2020.csv")
setwd("C:/Users/kaije/OneDrive - UW/UW Classes/STAT 403/STAT403Project/Scripts")
data <- read.csv("../Data/31119913_National2020.csv")
data_subset <- data[, cols]
data_subset[data_subset == " "] <- "Omit"
data_subset$age = relevel(factor(data_subset$age), ref = "18-29")
data_subset$sex = relevel(factor(data_subset$sex), ref = "Female")
data_subset$educ18 = relevel(factor(data_subset$educ18), ref = "Never attended college")
data_subset$income20 = relevel(factor(data_subset$income20), ref = "Omit")
data_subset$racism20 = relevel(factor(data_subset$racism20), ref = "Omit")
data_subset$life = relevel(factor(data_subset$life), ref = "Omit")
data_subset$region = relevel(factor(data_subset$region), ref = "South")
data_subset$sizeplac = relevel(factor(data_subset$sizeplac), ref = "Suburbs")
data_subset$votemeth = relevel(factor(data_subset$votemeth), ref = "Election day")
data_subset$abortion = relevel(factor(data_subset$abortion), ref = "Omit")
data_subset$facemask = relevel(factor(data_subset$facemask), ref = "Omit")
data_subset$lgbt = relevel(factor(data_subset$lgbt), ref = "Omit")
data_subset$climatec = relevel(factor(data_subset$climatec), ref = "Omit")
data_subset$y <- data_subset$pres == "Joe Biden"
B <- 10000
n = nrow(data_subset)
coeff_BT_lemp <- list()
for(i_BT in 1:B){
print(i_BT)
w = sample(n,n,replace = T)
data2_BT = data_subset[w,]
fit_BT = glm(y ~ age + sex + votemeth + abortion + educ18 + racism20 + income20 + sizeplac + climatec, family = "binomial", data = data2_BT)
coeff_BT_lemp[[i_BT]] <- fit_BT$coefficients
}
